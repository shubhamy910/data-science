{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "494a4f3b-d108-4d9f-9e22-a02ea13d9db3",
   "metadata": {},
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc41f33-4b9f-40c3-8da3-d47a2f2469dc",
   "metadata": {},
   "source": [
    "Answer1. \n",
    "\n",
    "To calculate the probability that an employee is a smoker given that he/she uses the health insurance plan, you can use Bayes' theorem. Let's denote:\n",
    "\n",
    "A: Event that an employee uses the health insurance plan. B: Event that an employee is a smoker. You are given:\n",
    "\n",
    "P(A) = Probability an employee uses the health insurance plan = 0.70 (70%) P(B|A) = Probability an employee is a smoker given they use the health insurance plan = 0.40 (40%)\n",
    "\n",
    "You want to find P(B|A), the probability that an employee is a smoker given they use the health insurance plan.\n",
    "\n",
    "Using Bayes' theorem: P(B/A) = (P(B) * P(A/B))/ P(A)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) = Probability an employee uses the health insurance plan given they are a smoker. This information is not given, but you can calculate it if you have the necessary data.\n",
    "\n",
    "Without information about P(A|B), you cannot directly calculate P(B|A). You would need additional data or assumptions about the relationship between smoking and using the health insurance plan to calculate P(A|B) and then use Bayes' theorem to find P(B|A).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f74482-ae12-4747-ad08-990cf94cf948",
   "metadata": {},
   "source": [
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f41a0-f30c-4acb-bfb5-b9132e841bdc",
   "metadata": {},
   "source": [
    "Answer2. \n",
    "\n",
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are both variants of the Naive Bayes algorithm used for classification tasks, but they have different underlying assumptions and are suited for different types of data:\n",
    "\n",
    "Bernoulli Naive Bayes: This variant is used when your feature vectors are binary (0/1) and represent the presence or absence of specific features. It assumes that each feature is binary and independent of each other. It's commonly used in text classification tasks, where each feature represents the presence or absence of a particular word in a document.\n",
    "\n",
    "Multinomial Naive Bayes: This variant is used when your feature vectors represent the frequency or count of discrete items, such as word counts in a document. It assumes that the features are generated from a multinomial distribution (hence the name) and also assumes independence among features. It's also commonly used in text classification but with frequency-based feature vectors.\n",
    "\n",
    "In summary, Bernoulli Naive Bayes works with binary data, while Multinomial Naive Bayes works with count or frequency data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d43fa5-71de-4f21-ad0d-fc1c6c640491",
   "metadata": {},
   "source": [
    "Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e04f449-c7c3-43d2-84b9-cb79451865e2",
   "metadata": {},
   "source": [
    "Answer3.  \n",
    "\n",
    "Bernoulli Naive Bayes, like other Naive Bayes variants, typically assumes that missing values are either treated as if they do not occur (0) or as if they do occur (1), depending on the specific application and how you choose to handle them.\n",
    "\n",
    "Treating missing values as 0: In this approach, missing values in the feature vector are treated as the absence of the corresponding feature. It assumes that if a feature's value is missing, it is as if that feature is not present for that instance. This can be suitable when the absence of a feature is meaningful.\n",
    "\n",
    "Treating missing values as 1: In this approach, missing values are treated as if they are present for all instances. This approach assumes that if a feature's value is missing, it is as if that feature has occurred with a value of 1 for that instance. This can be suitable when the presence of a feature is more important than its actual value.\n",
    "\n",
    "The choice between these approaches depends on the nature of your data and the problem you are trying to solve. You should carefully consider which method makes more sense in your specific context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6c4d2-6e5e-48b1-b034-6db3b17bbd04",
   "metadata": {},
   "source": [
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9c685-86e4-48c0-9735-c5c455a5037c",
   "metadata": {},
   "source": [
    "Answer4. \n",
    "\n",
    "Gaussian Naive Bayes is primarily designed for binary and continuous data, making it well-suited for binary classification problems. It models the likelihood of the features as Gaussian (normal) distributions.\n",
    "\n",
    "However, Gaussian Naive Bayes can also be adapted for multi-class classification problems by extending it to handle multiple classes. To do this, you would need to modify the algorithm to estimate the parameters (mean and variance) of the Gaussian distribution for each class and then use these parameters to calculate the likelihood of a given data point belonging to each class. The class with the highest likelihood would be the predicted class.\n",
    "\n",
    "In summary, yes, Gaussian Naive Bayes can be used for multi-class classification, but it requires some adjustments to handle multiple classes effectively. Other variants of Naive Bayes, like Multinomial Naive Bayes or Categorical Naive Bayes, are more commonly used for multi-class classification tasks, especially when dealing with discrete data or text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd7b85-acc8-4598-b469-42e568bb53e4",
   "metadata": {},
   "source": [
    "# Q5. Assignment:\n",
    "\n",
    "## Data preparation:\n",
    "\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "\n",
    "## Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "\n",
    "## Results:\n",
    "Report the following performance metrics for each classifier:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "\n",
    "## Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0783ab2f-f0d0-49c7-bf83-0d3345e59e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Download the dataset from the UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Save the dataset to a local CSV file\n",
    "with open(\"spambase.csv\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Load the dataset using Pandas\n",
    "data = pd.read_csv(\"spambase.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1988b2-3380-4fd6-9cf8-5f3a4b3f926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Initialize the classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "# Perform 10-fold cross-validation for each classifier\n",
    "def evaluate_classifier(classifier, X, y):\n",
    "    accuracy = cross_val_score(classifier, X, y, cv=10, scoring='accuracy').mean()\n",
    "    precision = cross_val_score(classifier, X, y, cv=10, scoring='precision').mean()\n",
    "    recall = cross_val_score(classifier, X, y, cv=10, scoring='recall').mean()\n",
    "    f1 = cross_val_score(classifier, X, y, cv=10, scoring='f1').mean()\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "accuracy_bernoulli, precision_bernoulli, recall_bernoulli, f1_bernoulli = evaluate_classifier(bernoulli_nb, X, y)\n",
    "accuracy_multinomial, precision_multinomial, recall_multinomial, f1_multinomial = evaluate_classifier(multinomial_nb, X, y)\n",
    "accuracy_gaussian, precision_gaussian, recall_gaussian, f1_gaussian = evaluate_classifier(gaussian_nb, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d080a9-3d9a-445a-b457-8f13da1c3bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes:\n",
      "Accuracy: 0.8839380364047911\n",
      "Precision: 0.8869617393737383\n",
      "Recall: 0.8152389047416673\n",
      "F1 Score: 0.8481249015095276\n",
      "\n",
      "Multinomial Naive Bayes:\n",
      "Accuracy: 0.7863496180326323\n",
      "Precision: 0.7393175533565436\n",
      "Recall: 0.7214983911116508\n",
      "F1 Score: 0.7282909724016348\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "Accuracy: 0.8217730830896915\n",
      "Precision: 0.7103733928118492\n",
      "Recall: 0.9569516119239877\n",
      "F1 Score: 0.8130660909542995\n"
     ]
    }
   ],
   "source": [
    "print(\"Bernoulli Naive Bayes:\")\n",
    "print(f\"Accuracy: {accuracy_bernoulli}\")\n",
    "print(f\"Precision: {precision_bernoulli}\")\n",
    "print(f\"Recall: {recall_bernoulli}\")\n",
    "print(f\"F1 Score: {f1_bernoulli}\")\n",
    "\n",
    "print(\"\\nMultinomial Naive Bayes:\")\n",
    "print(f\"Accuracy: {accuracy_multinomial}\")\n",
    "print(f\"Precision: {precision_multinomial}\")\n",
    "print(f\"Recall: {recall_multinomial}\")\n",
    "print(f\"F1 Score: {f1_multinomial}\")\n",
    "\n",
    "print(\"\\nGaussian Naive Bayes:\")\n",
    "print(f\"Accuracy: {accuracy_gaussian}\")\n",
    "print(f\"Precision: {precision_gaussian}\")\n",
    "print(f\"Recall: {recall_gaussian}\")\n",
    "print(f\"F1 Score: {f1_gaussian}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cc6d9f-9a1b-4c0c-95e6-ea87c3c56948",
   "metadata": {},
   "source": [
    "# conclusion\n",
    "\n",
    "- As we can see that multinomial Naive Bayes have low accuracy,precision,recall,F1 score compare to Bernoulli and Gaussian\n",
    "- Where Bernoulli has more accuracy than Gaussian but we can see that this case is about Recall so in Gaussisan Naive bayes recall is 95% so that we can select Gaussian Naive bayes and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080e70e-d7b9-4748-be76-d060bfcd1a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
